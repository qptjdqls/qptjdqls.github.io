---
layout: post
title: InfoGAN
date: 2022-08-08 11:59:59 +0900
categories: DL
---

# InfoGAN

## 원본 글: [jonathan-hui.medium.com](https://jonathan-hui.medium.com/gan-cgan-infogan-using-labels-to-improve-gan-8ba4de5f9c3d)

## 1. Using labels to import GAN
In GAN, traning models are non-trivial. It can take extra help from the labes to make the model performing better.

## 2. CGAN
Vanilla GAN 에서는 생성할 데이터의 mode 에 대한 제어를 할 방법이 없다. CGAN 은 label $y$ 를 인풋에 같이 넣어줌으로써 generator 가 해당하는 라벨에 맞는 이미지를 생성하기를 바라는 방법.

> $\underset{G}{\min}\underset{D}{\max}V(D,G)=\mathbb{E}_{x\sim p_{data}(x)}[\log D(x|y)]+\mathbb{E}_{z\sim p_z(z)}[\log (1-D(G(z|y)))]$

<center><img src="./../_site/public/img/2022-08-08-InfoGAN/CGAN.png" width=75%></center>

CGAN 의 구조에서 확인할 수 있듯이 real image & label pair 가 필요하다. label 은 (MNIST 에서) $y\approx~U(0,9)$ 에 국한 된 것이 아니라 stroke size 등의 prior 를 모두 사용하면 된다.

## 3. InfoGAN
CGAN 과 같이 주어진 label $y$ 만 활용하는 것이 아니라, distriminator 를 통해 이러한 latent feature 들을 모두 추출할 수 있도록 한다. <br/>
CGAN 과 동일한 방법으로 single feature $c\sim U(0,9)$ 를 샘플링 하고 인풋으로 함께 들어간다. Discriminator 는 discrimination 외에도 $Q(c|x)$ 를 $c$ 와 유사한 분포를 출력하도록 학습되고, 방법은 $c$ 와 $G(z,c)$ 의 mutual information 이 최대가 되도록 하는 것이다. 

> $\underset{G}{\min}\underset{D}{\max}V_{infoGAN}(D,G)=V_{GAN}(D,G)-\lambda I(c;G(z,c))$
>> $V_{GAN}=\mathbb{E}_{x\sim p_{data}(x)}[\log D(x)]+\mathbb{E}_{z\sim p_z(z)}[\log (1-D(G(z,c)))]$

<center><img src="./../_site/public/img/2022-08-08-InfoGAN/InfoGAN.png" width=75%></center>

---
## 원본 글: [https://jaejunyoo.blogspot.com/](https://jaejunyoo.blogspot.com/2017/03/infogan-1.html)

## 4. Variational Mutual Information Maximization
