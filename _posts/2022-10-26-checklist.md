---
layout: post
title: checklist
date: 2022-10-26 11:59:59 +0900
categories: etc
permalink: /28
---

# checklist

0. What did you do during all day?
   - 하루 동안 한 일 자세하게 작성

1. [Bill Evans](https://www.youtube.com/watch?v=anH8Y8vAz2Q&t=110s)
   - 자신이 어느 단계에 있는지 알고 진실되고, 현실적이고 정확하게 수행해야 한다.
   - 사람들은 작은 부분을 현실적으로 해결하려는 대신 하나로 뭉뚱그려서 커다란 문제로 본다.
   - 한번에 모든 것을 할 수 없다. 모든 문제를 가져와서 이것을 하나의 큰 문제로 만들면 무언가 잡히는 것 같겠지만 전혀 그렇지 않다.

2. [Kurzgesagt](https://www.youtube.com/watch?v=75d_29QWELk)
   - easy situation 이 trigger 가 되게 해서 hard action 을 습관으로 만들수 있다. 

- [ ] 10:00 까지 목표 지점 도착 
- [ ] 21:00 까지 외부에 있기
- [ ] 공간을 목적에 따라 구분
- [ ] 이상할 때, 내가 잘못 이해한것 같을 때, 수상할 때 가장 먼저 질문, 문제 해결
- [ ] 기록하는 습관
- [x] 컴퓨터를 켰을 때 가장 먼저 blog 에 어떤 글이라도 작성
- [x] 컴퓨터를 켰을 때 가장 먼저 'Effective python' 에 대해 작은 분량이라도 정리
- [x] 누웠을 때 핸드폰 보기 전에 '수학으로 풀어보는 강화학습' 보기
- [x] 누웠을 때 핸드폰 볼때 누워서 하는 운동
- [x] 누웠을 때 핸드폰 볼때 유명 연구/개발자 SNS 확인
- [x] 잠에서 깨면 핸드폰 보기 전에 일어나서 물 마시기
- [x] 잠에서 깨면 핸드폰 보기 전에 일어나서 비타민 먹기
- [x] 12~02 시 사이에 점심 먹기
- [x] 18~20 시 사이에 저녁 먹기

---
- <span style="color: red">**EMERGENCY**</span>


- **IN PROGRESS**
  - Effective python
  - 수학으로 풀어보는 강화학습 원리와 알고리즘
  - 수학으로 풀어보는 강화학습 원리와 알고리즘 pytorch
  - [RL bootcamp](https://sites.google.com/view/deep-rl-bootcamp/lectures)


- **ICE BOX (<U>MAXLEN=5</U>)**
  - [ ] Why does the optimal policy exist?
    - https://towardsdatascience.com/why-does-the-optimal-policy-exist-29f30fd51f8c
  - [ ] https://sites.ualberta.ca/~szepesva/papers/RLAlgsInMDPs.pdf
  - [ ] [InfoGAN 논문 재작성](https://www.inference.vc/infogan-variational-bound-on-mutual-information-twice/)
    - uppder bound of mutual information
    - [On Information Theoretic Bounds for SGD](https://www.inference.vc/on-information-theoretic-bounds-for-sgd/)
    - [openai code](https://github.com/openai/InfoGAN/blob/master/infogan/algos/infogan_trainer.py)
  
- **FREEZER (<U>MAXLEN=10</U>)**
  - [ ] David Silver lecture 부족한 부분
  - [ ] 강화학습이론 강의
  - [ ] [VAE, reparametrization trick](https://jaejunyoo.blogspot.com/2017/04/auto-encoding-variational-bayes-vae-1.html)
    - [PR-010: Auto-Encoding Variational Bayes, ICLR 2014](https://www.youtube.com/watch?v=KYA-GEhObIs&list=PLlMkM4tgfjnJhhd4wn5aj8fVTYJwIpWkS&index=12)
  - [ ] Meausre theory
  - [ ] Kaggle
  - [ ] ICML 2022 review
  - [ ] Information Geometry
    - [ ] https://franknielsen.github.io/
    - [ ] https://www.youtube.com/watch?v=FlyJJIQo-g4&list=PLHZhjPByiV3L94AeJ9FcK1yrnRDOt3Vit
  - [ ] AlphaGo Zero
  - [ ] [Self-Normalizing Neural Networks](https://arxiv.org/abs/1706.02515)

- **COMPLETE**
  - [x] Batch normalization
  - [x] [How to study RL](https://github.com/reinforcement-learning-kr/how_to_study_rl)
  - [x] Central limit theorem 
  - [x] Law of total probability, expectation, and variance
  - [x] **논리적 사고와 추론**
  - [x] Jensen-Shannon divergence python code
  - [x] DQN: Cartpole
  - [x] DDQN: Mario
  - [x] Gitbook [Fundamental of Reinforcment Learning](https://dnddnjs.gitbooks.io/rl/content/)

---

- 2022/11/12
  - [x] checklist 작성
- 2022/11/13
  - [x] problem set 2
- 2022/11/14
  - [x] review paper
    - [ ] SAC
    - [ ] (이전 발표자들 자료 정리)
  - [ ] Decision transformer 읽기
  - [ ] MADDPG 
- 2022/11/15
  - [ ] review paper
    - [ ] Dream to Control: Learning Behaviors by Latent Imagination
    - [ ] SAC
    - [ ] (이전 발표자들 자료 정리)
  - [ ] Decision transformer 
    - [ ] test
    - [ ] ppt
  - [ ] MADDPG
    - [ ] test
  - [ ] 정보이론 과제
- 2022/11/16
  - - [x] review paper
    - [x] Dream to Control: Learning Behaviors by Latent Imagination
    - [ ] SAC
    - [ ] (이전 발표자들 자료 정리)
  - [x] Decision transformer 
    - [ ] test
    - [x] ppt
  - [ ] MADDPG
    - [ ] test
  - [x] 정보이론 과제
- 2022/11/17
  - [ ] Cellpose / NMF / EXTRACT 중 택 1
  - [ ] Imitation learning paper reading
  - [ ] MADDPG